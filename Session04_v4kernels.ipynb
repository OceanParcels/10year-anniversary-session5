{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0311e831",
   "metadata": {},
   "source": [
    "# Workshop on how to update Kernels to use Parcels v4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54f21c8",
   "metadata": {},
   "source": [
    "As mentioned in the presentation, the main changes to Kernels in Parcels v4 are:\n",
    "\n",
    "- In Kernels, use actual dates, rather than seconds from start of FieldSet.\n",
    "\n",
    "- `particle.dt` is now a `np.timedelta64`. Be aware when you do `x = v * dt`!\n",
    "\n",
    "- The 'signature' of the Kernel changes from `Kernel(particle, fieldset, time)` to `Kernel(particles, fieldset)`, so no more `time`. Use `particle.time` instead.\n",
    "\n",
    "- `particle_dlon` etc. has been changed to `particle.dlon`.\n",
    "\n",
    "- The `particle.delete()` method has been removed. Delete particles by setting their state to `StatusCode.Delete`.\n",
    "\n",
    "- Kernels now run as separate functions, not as one large concatenated function. This means that variables defined in one Kernel are not available in the next Kernel.\n",
    "\n",
    "- No more `if`-statements. Use `np.where` instead.\n",
    "\n",
    "- Support for python functions in Kernels.\n",
    "\n",
    "- Support for arrays and `for`-loops in Kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e786acc1",
   "metadata": {},
   "source": [
    "## Simple Kernels that operate on all Particles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a332a4",
   "metadata": {},
   "source": [
    "Many Kernels will be easy to update, as they operate on all particles in the same way. For example, a Kernel that moves particles eastward by 1 m/s can be updated as follows:\n",
    "\n",
    "```python\n",
    "def MoveEast(particles, fieldset):\n",
    "    dt = particles.dt / np.timedelta64(1, 's')  # Convert dt to seconds\n",
    "    particles.dlon += 1 * dt\n",
    "```\n",
    "\n",
    "Note that in the above code, we are using the `dt` variable to represent the time step as a `float`, which is needed because `particles.dlon` is also a `float`. We are still considering how to make this more elegant for the final release of Parcels v4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80767ffe",
   "metadata": {},
   "source": [
    "#### **Exercise**: Convert the Kernels from Session 2 yesterday to the new format and test whether they work.\n",
    "\n",
    "In order to run them, you will also need to create a new `FieldSet`. The easiest way to do that is using the new `FieldSet.from_copernicusmarine()` method:\n",
    "\n",
    "```python\n",
    "example_dataset_folder = download_example_dataset(\"CopernicusMarine_data_for_Argo_tutorial\")\n",
    "ds_cm = xr.open_mfdataset(f\"{example_dataset_folder}/*.nc\", combine=\"by_coords\")\n",
    "fieldset = FieldSet.from_copernicusmarine(ds_cm)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534163bb",
   "metadata": {},
   "source": [
    "The code above downloads a (very) small region in the Agulhas current. If this does not work for you, you could use the [`copernicusmarine` toolbox](https://help.marine.copernicus.eu/en/articles/7949409-copernicus-marine-toolbox-introduction) to download a different region. You'll need to have a login for the Copernicus Marine Service, but you can create one for free [here](https://marine.copernicus.eu/).\n",
    "\n",
    "You can then download the data with e.g. this script:\n",
    "\n",
    "```python\n",
    "import copernicusmarine\n",
    "\n",
    "for var, fname in zip(([\"uo\", \"vo\"], [\"thetao\"], [\"so\"]), (\"cur\", \"thetao\", \"so\")):\n",
    "    copernicusmarine.subset(\n",
    "        dataset_id=f\"cmems_mod_glo_phy-{fname}_anfc_0.083deg_P1D-m\",\n",
    "        variables=var,\n",
    "        minimum_longitude=31,  # adjust to your region of interest\n",
    "        maximum_longitude=33,  # adjust to your region of interest\n",
    "        minimum_latitude=-33,  # adjust to your region of interest\n",
    "        maximum_latitude=-30,  # adjust to your region of interest\n",
    "        start_datetime=\"2024-01-01T00:00:00\",\n",
    "        end_datetime=\"2024-02-01T00:00:00\",\n",
    "        minimum_depth=0,\n",
    "        maximum_depth=2000,  # adjust to your depth of interest\n",
    "        username=#YOUR_USERNAME#,\n",
    "        password=#YOUR_PASSWORD#,\n",
    "        coordinates_selection_method=\"outside\",\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e992a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04fde02",
   "metadata": {},
   "source": [
    "One of the very nice features of pure-python Kernels is that you can now use any python function in your Kernel. For example, you can use the `gsw` toolbox to compute density from temperature and salinity.\n",
    "\n",
    "#### **Exercise**: write a Kernel that computes density from temperature and salinity using the `gsw` toolbox.\n",
    "\n",
    "For this, you can use the same `fieldset` as above, which contains temperature and salinity fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6902eaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e3e705",
   "metadata": {},
   "source": [
    "## More complex Kernels that operate on subsets of Particles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ec7b03",
   "metadata": {},
   "source": [
    "One of the biggest changes you may have to deal with is the removal of `if`-statements in Kernels. Since the Kernel now operates on all particles at once, `if`-statements are not allowed anymore. Instead, you should use `np.where` to operate on subsets of particles. For example, a Kernel that deletes particles older than 10 can be written as:\n",
    "\n",
    "```python\n",
    "def DeleteOldParticles(particles, fieldset):\n",
    "    particles.state = np.where(particles.age > 10,\n",
    "                               StatusCode.Delete,\n",
    "                               particles.state)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae4c351",
   "metadata": {},
   "source": [
    "#### **Exercise**: Convert a Kernel with `if`-statements to the new format using `np.where`\n",
    "\n",
    "For this, you should ideally take a Kernel that you have written before. If you haven't written one before, you can first make one in the v3 format, and then convert it to the v4 format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dae01c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873b12b4",
   "metadata": {},
   "source": [
    "## Fallback option, looping over particles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ed9462",
   "metadata": {},
   "source": [
    "Of course, if it's really impossible to avoid `if`-statements, you can always loop over particles in a Kernel. This is less efficient, but it works. Here's an example of how to do this:\n",
    "\n",
    "```python\n",
    "def DeleteOldParticles_forloop(particles, fieldset):\n",
    "    for p in particles:\n",
    "        if p.age > 10:\n",
    "            p.state = StatusCode.Delete\n",
    "```\n",
    "\n",
    "Note that we are exploring whether `numba` can be used to speed up such Kernels, but this is not yet implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afb75e9",
   "metadata": {},
   "source": [
    "#### **Exercise**: Test if your v4-kernel also works with a `for`-loop.\n",
    "\n",
    "Explore the difference in speed between the `np.where` and the `for`-loop version of your Kernel. For this, you will probably have to run it with thousands of particles.\n",
    "\n",
    "If you want, you could even try to get `numba` to work with the `for`-loop version of your Kernel. We'd be very keen to hear how that goes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fcb2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee01383e",
   "metadata": {},
   "source": [
    "## Extra: write custom Interpolators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770df2e2",
   "metadata": {},
   "source": [
    "One of the new features in Parcels v4 is the ability to write custom Interpolators. This is a bit more advanced, but if you are interested, you can try it out yourself. \n",
    "\n",
    "We are still working on the definitive API, but for now an Interpolator function must have the following signature:\n",
    "\n",
    "```python\n",
    "\n",
    "def my_interpolator(\n",
    "    field: Field,\n",
    "    ti: int,\n",
    "    position: dict[_XGRID_AXES, tuple[int, float | np.ndarray]],\n",
    "    tau: np.float32 | np.float64,\n",
    "    t: np.float32 | np.float64,\n",
    "    z: np.float32 | np.float64,\n",
    "    y: np.float32 | np.float64,\n",
    "    x: np.float32 | np.float64,\n",
    ") -> np.float32 | np.float64:\n",
    "    return 0.0\n",
    "```\n",
    "Where of course an Interpolator that always returns 0.0 is not very useful, so the function itself will be much more complex. \n",
    "\n",
    "The `position` argument is a dictionary that contains, for each dimension, a tuple of the index of the grid cell and the relative position within that grid cell. For example, for a 2D field, `position` could be:\n",
    "\n",
    "```python\n",
    "{\n",
    "    'X': (10, 0.3),  # 10th grid cell in X direction, 30% into the cell\n",
    "    'Y': (20, 0.7)   # 20th grid cell in Y direction, 70% into the cell\n",
    "}\n",
    "```\n",
    "\n",
    "And `ti` and `tau` are the same for the time dimension. A very simple horizontal linear interpolation could thus be written as:\n",
    "\n",
    "```python\n",
    "def linear_interpolator(field, ti, position, tau, t, z, y, x):\n",
    "    \"\"\"Bilinear interpolation on a rectilinear grid.\"\"\"\n",
    "    xi, xsi = position[\"X\"]\n",
    "    yi, eta = position[\"Y\"]\n",
    "\n",
    "    data = field.data.data[ti:ti + 2, zi, yi:yi + 2, xi:xi + 2]\n",
    "    val_t0 =(\n",
    "        (1 - xsi) * (1 - eta) * data[0, 0, 0, 0]\n",
    "        + xsi * (1 - eta) * data[0, 0, 0, 1]\n",
    "        + xsi * eta * data[0, 0, 1, 1]\n",
    "        + (1 - xsi) * eta * data[0, 0, 1, 0]\n",
    "    )\n",
    "\n",
    "    val_t1 =(\n",
    "        (1 - xsi) * (1 - eta) * data[1, 0, 0, 0]\n",
    "        + xsi * (1 - eta) * data[1, 0, 0, 1]\n",
    "        + xsi * eta * data[1, 0, 1, 1]\n",
    "        + (1 - xsi) * eta * data[1, 0, 1, 0]\n",
    "    )\n",
    "    value = (val_t0 * (1 - tau) + val_t1 * tau)\n",
    "    return value.compute() if is_dask_collection(value) else value\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412a4f96",
   "metadata": {},
   "source": [
    "#### **Exercise**: Write a custom Interpolator function that does something useful.\n",
    "\n",
    "You can test your interpolator by setting it as the `Field.interp_method`:\n",
    "\n",
    "```python\n",
    "fieldset.U.interp_method = my_interpolator\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706203cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parcels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
